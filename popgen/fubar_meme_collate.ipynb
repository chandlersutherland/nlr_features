{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458ccdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import glob\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5447574",
   "metadata": {},
   "source": [
    "Goal: gather pertinent info from hyphy log files, make into a single dataframe with proportion of codons identified to be under positive selection. Each software produces a slightly different log file, so define functions for each one to correctly parse.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9076f47f",
   "metadata": {},
   "source": [
    "Start with MEME analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d47234",
   "metadata": {},
   "outputs": [],
   "source": [
    "#wrangle logs for all branches and just internal branches\n",
    "meme_logs=glob.glob(os.path.join('/global/scratch/users/chandlersutherland/e14/popgen/clades/*/hyphy_meme.log'))\n",
    "meme_internal_logs=glob.glob(os.path.join('/global/scratch/users/chandlersutherland/e14/popgen/clades/*/hyphy_meme_internal.log'))\n",
    "len(meme_internal_logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2486fbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a function that takes in the file path, and returns the row index of the sites df in the log file if sites are under selection \n",
    "def number_hunter_meme(file_path):\n",
    "    with open(file_path, 'r') as file: \n",
    "        file_contents=file.readlines()\n",
    "        for row in file_contents: \n",
    "            if row.find('Empty File') != -1:\n",
    "                print('Error, empty file. Probably no tree file.')\n",
    "                start=np.nan\n",
    "                end=np.nan\n",
    "                codon_len=np.nan\n",
    "            elif row.find('Loaded a multiple') != -1:\n",
    "                codon_len=int(row.split('**')[3])\n",
    "            elif row.find('### ** Found _0_') != -1:\n",
    "                print('zero sites under positive selection')\n",
    "                start=0\n",
    "                end=0\n",
    "            elif row.find('Episodic selection detected?') != -1:\n",
    "                start=file_contents.index(row)\n",
    "            elif row.find('### ** Found') != -1:\n",
    "                end=file_contents.index(row)\n",
    "            \n",
    "    return(start, end, codon_len)\n",
    "\n",
    "#define a function that takes in the row indices from number_hunter, the codon length from number_hunter, and the file path \n",
    "#this function 1) writes the positions to a csv in the clade directory and 2) returns that dataframe for processing \n",
    "def file_convert_meme(start, end, codon_len, file_path):\n",
    "    positions=pd.DataFrame()\n",
    "    clade=file_path.split('/')[-2]\n",
    "    if np.isnan(start) == True:\n",
    "        row_res={'clade':clade, 'codon_len':np.nan, 'codon':np.nan, 'parititon':np.nan, 'alpha':np.nan, 'beta':np.nan, 'LRT':np.nan, 'p':np.nan}\n",
    "        positions=positions.append(row_res, ignore_index=True) #return a blank df if no tree file \n",
    "        print('error, no file')\n",
    "    elif start==0:\n",
    "        row_res={'clade':clade, 'codon_len':codon_len, 'codon':np.nan, 'parititon':np.nan, 'alpha':np.nan, 'beta':np.nan, 'LRT':np.nan, 'p':1}\n",
    "        positions=positions.append(row_res, ignore_index=True)\n",
    "        print('no positions under selection')\n",
    "    else:\n",
    "        with open(file_path, 'r') as file: \n",
    "            file_contents=file.readlines()\n",
    "            for l_no, line in enumerate(file_contents[start+2:end-1]):\n",
    "                line_string=line.split(' ')\n",
    "                while(\"\" in line_string):\n",
    "                    line_string.remove(\"\")\n",
    "                codon=line_string[1]\n",
    "                partition=line_string[3]\n",
    "                alpha=line_string[5]\n",
    "                beta=line_string[7]\n",
    "                LRT=line_string[11]\n",
    "                p=line_string[-4]\n",
    "                if LRT == 'Yes,':\n",
    "                    LRT=line_string[9]\n",
    "                row_res={'clade':clade, 'codon_len':int(codon_len), 'codon':int(codon), 'parititon':int(partition), 'alpha':float(alpha), 'beta':float(beta), 'LRT':float(LRT), 'p':float(p)}\n",
    "                positions=positions.append(row_res, ignore_index=True)\n",
    "        output_csv=file_path.strip('hyphy_meme.log')+'hyphy_meme_pos.csv'\n",
    "        positions.to_csv(output_csv)\n",
    "    return positions\n",
    "\n",
    "#finally a function that wraps these functions\n",
    "def wrapper_meme(file_path):\n",
    "    #file_path=meme_logs[i]\n",
    "    index=number_hunter_meme(file_path)\n",
    "    positions=file_convert_meme(index[0], index[1], index[2], file_path)\n",
    "    return positions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8dec07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply to meme_logs and meme_internal logs \n",
    "meme=pd.DataFrame()\n",
    "for i in meme_logs:\n",
    "    res=wrapper_meme(i)\n",
    "    meme=meme.append(res)\n",
    "\n",
    "meme_counts=meme.groupby(['clade', 'codon_len'])['p'].apply(lambda x:(x<0.05).sum()).reset_index().rename(columns={'p':'meme_count_95'})\n",
    "meme_counts['prop_meme_95']=meme_counts['meme_count_95']/meme_counts['codon_len']\n",
    "\n",
    "meme_internal=pd.DataFrame()\n",
    "for i in meme_internal_logs:\n",
    "    res=wrapper_meme(i)\n",
    "    meme_internal=meme_internal.append(res)\n",
    "    \n",
    "meme_internal_counts=meme_internal.groupby(['clade', 'codon_len'])['p'].apply(lambda x:(x<0.05).sum()).reset_index().rename(columns={'p':'meme_count_95'})\n",
    "meme_internal_counts['prop_meme_internal_95']=meme_internal_counts['meme_count_95']/meme_internal_counts['codon_len']\n",
    "\n",
    "meme_results=pd.merge(meme_counts[['clade', 'codon_len', 'prop_meme_95']], meme_internal_counts[['clade', 'prop_meme_internal_95']], on='clade')\n",
    "meme_results.to_csv('/global/scratch/users/chandlersutherland/e14/popgen/meme_results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c972104",
   "metadata": {},
   "source": [
    "Repeat for FEL results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d080e671",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get paths to fel files \n",
    "fel_internal_logs=glob.glob(os.path.join('/global/scratch/users/chandlersutherland/e14/popgen/clades/*/hyphy_fel_internal.log'))\n",
    "fel_logs=glob.glob(os.path.join('/global/scratch/users/chandlersutherland/e14/popgen/clades/*/hyphy_fel.log'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198f0b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_hunter_fel(file_path):\n",
    "    with open(file_path, 'r') as file: \n",
    "        file_contents=file.readlines()\n",
    "        for row in file_contents: \n",
    "            if row.find('Empty File') != -1:\n",
    "                print('Error, empty file. Probably no tree file.')\n",
    "                start=np.nan\n",
    "                end=np.nan\n",
    "                codon_len=np.nan\n",
    "                break\n",
    "            elif row.find('Loaded a multiple') != -1:\n",
    "                codon_len=int(row.split(\"**\")[3])\n",
    "            elif row.find('Found _0_ sites under pervasive positive diversifying and _0_ sites under negative selection') != -1:\n",
    "                start=0\n",
    "                end=0\n",
    "            elif row.find('these sites are significant') != -1:\n",
    "                start=file_contents.index(row)\n",
    "            elif row.find('under pervasive positive') != -1:\n",
    "                end=file_contents.index(row)\n",
    "    return(start, end, codon_len)\n",
    "\n",
    "def file_convert_fel(start, end, codon_len, file_path):\n",
    "    positions=pd.DataFrame()\n",
    "    clade=file_path.split('/')[-2]\n",
    "    if np.isnan(start) == True:\n",
    "        row_res={'clade':clade, 'codon_len':np.nan, 'codon':np.nan, 'parititon':np.nan, 'alpha':np.nan, 'beta':np.nan, 'LRT':np.nan, 'p':np.nan}\n",
    "        positions=positions.append(row_res, ignore_index=True) #return a blank df if no tree file \n",
    "        #print('error, no file')\n",
    "    elif start==0:\n",
    "        row_res={'clade':clade, 'codon_len':codon_len, 'codon':np.nan, 'parititon':np.nan, 'alpha':np.nan, 'beta':np.nan, 'LRT':np.nan, 'p':1}\n",
    "        positions=positions.append(row_res, ignore_index=True)\n",
    "        #print('no positions under selection')\n",
    "    else:\n",
    "        with open(file_path, 'r') as file: \n",
    "            file_contents=file.readlines()\n",
    "            for l_no, line in enumerate(file_contents[start+4:end-1]):\n",
    "                line_string=line.split(' ')\n",
    "                while(\"\" in line_string):\n",
    "                    line_string.remove(\"\")\n",
    "                codon=line_string[1]\n",
    "                partition=line_string[3]\n",
    "                alpha=line_string[5]\n",
    "                beta=line_string[7]\n",
    "                LRT=line_string[9]\n",
    "                p=line_string[-2]\n",
    "                direction=line_string[11]\n",
    "                #if LRT == 'Yes,':\n",
    "                #    LRT=line_string[9]\n",
    "                row_res={'clade':clade, 'codon_len':int(codon_len), 'codon':int(codon), 'parititon':int(partition), 'alpha':float(alpha), 'beta':float(beta), 'LRT':float(LRT), 'direction':direction, 'p':float(p)}\n",
    "                positions=positions.append(row_res, ignore_index=True)\n",
    "        output_csv=file_path.strip('hyphy_fel_internal.log')+'hyphy_fel_internal_pos.csv'\n",
    "        positions.to_csv(output_csv)\n",
    "    return positions\n",
    "\n",
    "def wrapper_fel(file_path):\n",
    "    #file_path=fel_logs[i]\n",
    "    index=number_hunter_fel(file_path)\n",
    "    positions=file_convert_fel(index[0], index[1], index[2], file_path)\n",
    "    return positions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b4ba3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fel_internal=pd.DataFrame()\n",
    "for i in fel_internal_logs:\n",
    "    res=wrapper_fel(i)\n",
    "    fel_internal=fel_internal.append(res)\n",
    "\n",
    "fel=pd.DataFrame()\n",
    "for i in fel_logs:\n",
    "    #print(fel_internal_logs[i])\n",
    "    res=wrapper_fel(i)\n",
    "    fel=fel.append(res)\n",
    "\n",
    "fel_internal_counts=fel_internal.groupby(['clade', 'codon_len', 'direction'])['p'].apply(lambda x:(x<0.05).sum()).reset_index().rename(columns={'p':'fel_count_95'})\n",
    "fel_internal_counts['prop_fel_int_95']=fel_internal_counts['fel_count_95']/fel_internal_counts['codon_len']\n",
    "fel_internal_counts=fel_internal_counts[['clade', 'direction', 'prop_fel_int_95']]\n",
    "\n",
    "fel_counts=fel.groupby(['clade', 'codon_len', 'direction'])['p'].apply(lambda x:(x<0.05).sum()).reset_index().rename(columns={'p':'fel_count_95'})\n",
    "fel_counts['prop_fel_95']=fel_counts['fel_count_95']/fel_counts['codon_len']\n",
    "fel_counts[['clade', 'direction', 'prop_fel_95']]\n",
    "\n",
    "fel_results=pd.merge(fel_internal_counts, fel_counts[['clade', 'direction', 'prop_fel_95']], on=['clade', 'direction'])\n",
    "fel_results.to_csv('/global/scratch/users/chandlersutherland/e14/popgen/fel_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93274905",
   "metadata": {},
   "outputs": [],
   "source": [
    "fel_internal\n",
    "fel_internal.to_csv('/global/scratch/users/chandlersutherland/e14/popgen/fel_internal_positions.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
